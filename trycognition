from tkinter import *
from tkinter import ttk
from PIL import Image, ImageTk
from tkinter import messagebox
import mysql.connector
from time import strftime
from datetime import datetime
import cv2
import os
import numpy as np
import mediapipe as mp
import time

def detect_fatigue_from_camera(blink_threshold=0.21, fatigue_blink_rate_threshold=20):
    mp_face_mesh = mp.solutions.face_mesh
    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)

    cap = cv2.VideoCapture(0)
    blink_count = 0
    closed_frames = 0
    start_time = time.time()

    def get_eye_aspect_ratio(landmarks, eye_indices):
        top = (landmarks[eye_indices[1]].y + landmarks[eye_indices[2]].y) / 2
        bottom = (landmarks[eye_indices[4]].y + landmarks[eye_indices[5]].y) / 2
        vertical = abs(top - bottom)
        horizontal = abs(landmarks[eye_indices[0]].x - landmarks[eye_indices[3]].x)
        return vertical / horizontal if horizontal != 0 else 0

    left_eye = [33, 160, 158, 133, 153, 144]
    right_eye = [362, 385, 387, 263, 373, 380]

    fatigue_report = {
        "status": "Analyzing...",
        "blink_count": 0,
        "recommendation": ""
    }

    return cap, face_mesh, left_eye, right_eye, get_eye_aspect_ratio, fatigue_report

class Face_Recognition:
    def __init__(self, root):
        self.root = root
        self.root.geometry("1530x790+0+0")
        self.root.title("Face Recognition System")

        self.counter = 0
        self.total = 0

        title_lbl = Label(self.root, text="Face recognition", font=("times new roman", 35, "bold"), bg="white", fg="pink")
        title_lbl.place(x=0, y=0, width=1530, height=60)

        # first image
        img_top = Image.open(r"my_images\details.jpeg")
        img_top = img_top.resize((650, 700), Image.ANTIALIAS)
        self.photoimg_top = ImageTk.PhotoImage(img_top)

        f_lbl = Label(self.root, image=self.photoimg_top)
        f_lbl.place(x=0, y=60, width=650, height=700)

        # second image
        img_bottom = Image.open(r"my_images\details.jpeg")
        img_bottom = img_bottom.resize((950, 700), Image.ANTIALIAS)
        self.photoimg_bottom = ImageTk.PhotoImage(img_bottom)

        f_lbl = Label(self.root, image=self.photoimg_bottom)
        f_lbl.place(x=650, y=60, width=950, height=700)

        # button
        button1 = Button(f_lbl, text="Face Recognition", command=self.face_recog, cursor="hand2", font=("times new roman", 18, "bold"), bg="white", fg="pink")
        button1.place(x=350, y=600, width=200, height=40)

    ############################## ATTENDANCE ##############################
    def mark_attendance(self, i, r, n, d):
        with open("todaysattendance.csv", "r+", newline="\n") as f:
            myDataList = f.readlines()
            name_list = []
            for line in myDataList:
                entry = line.split(",")
                name_list.append(entry[0])
            if((i not in name_list) and (r not in name_list) and (n not in name_list) and (d not in name_list)):
                now = datetime.now()
                d1 = now.strftime("%d/%m/%Y")
                dtString = now.strftime("%H:%M:%S")
                f.writelines(f"\n{i},{r},{n},{d},{dtString},{d1},Present")

    ############################## FACE RECOGNITION ##############################
    def face_recog(self):
        def recognize(img, face_mesh, left_eye, right_eye, get_eye_aspect_ratio, fatigue_report):
            # Convert to RGB
            frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(frame_rgb)

            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    lm = face_landmarks.landmark

                    left_ear = get_eye_aspect_ratio(lm, left_eye)
                    right_ear = get_eye_aspect_ratio(lm, right_eye)
                    ear = (left_ear + right_ear) / 2.0

                    # Check for blink
                    if ear < 0.21:
                        self.counter += 1
                    else:
                        if self.counter >= 2:
                            self.total += 1

                        self.counter = 0

                    cv2.putText(img, f"EAR: {ear:.2f}", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(img, f"Blinks: {self.total}", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

                    # Mark attendance if blink count is high enough
                    if self.total >= 20:
                        # Assuming user data is available here
                        # mark_attendance(i, r, n, d) - needs real user data to work

                        cv2.putText(img, "Attendance Marked", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

            return img

        # Initialize MediaPipe face mesh
        cap, face_mesh, left_eye, right_eye, get_eye_aspect_ratio, fatigue_report = detect_fatigue_from_camera()

        while True:
            ret, img = cap.read()
            if not ret:
                break

            img = recognize(img, face_mesh, left_eye, right_eye, get_eye_aspect_ratio, fatigue_report)
            cv2.imshow("Face Recognition with Fatigue Detection", img)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:
                break

        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    root = Tk()
    obj = Face_Recognition(root)
    root.mainloop()
